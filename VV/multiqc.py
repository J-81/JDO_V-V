import zipfile
import tempfile
import os
from pathlib import Path
import json
from typing import Tuple
from statistics import median
import logging
log = logging.getLogger(__name__)

from VV.utils import readsWise_outlier_check
from VV.flagging import Flagger
Flagger = Flagger(script=Path(__file__).name)

# TODO:
    # check total sequences between paired reads match
    # log total sequences max,med,min
    # log percent duplicates max,med,min
    # log percent GC max,med,min

class MultiQC():
    """ Representation of all MultiQC data.
    """
    def __init__(self,
                 multiQC_out_path,
                 samples,
                 paired_end,
                 outlier_thresholds):
        # using non-zipped path, generated by multiqc by default
        # json_file = self._json_multiQC(multiQC_zip_path)
        json_file = os.path.join(multiQC_out_path, "multiqc_data.json")
        with open(json_file, "r") as f:
            data = json.load(f)
        self.data = data
        self.paired_end = paired_end
        self.samples = samples
        # TODO: assert this matches required signature for outlier checks
        self.outlier_thresholds = outlier_thresholds
        self.sample_mapping = self._map_samples()
        if self.paired_end:
            self._check_pair_counts_match()

        self._check_outliers()

        for data_source in self.data['report_data_sources'].keys():
            log.debug(f"Found MultiQC data sourced from {data_source}")
            if data_source == "FastQC":
                log.debug(f"Loading FastQC")
                self.fastQC = self._load_fastQC()
            else:
                log.debug(f"Loading {data_source}: not implemented")

    def _map_samples(self):
        """ Maps each sample to the sample files detected in multiQC

        sample: (forward_data, reverse_data)
        """
        mapping = dict()
        data = self.data['report_general_stats_data'][0]
        forward = None
        reverse = None
        for sample in self.samples:
            for read_name, read_data in data.items():
                if sample in read_name and "R1" in read_name:
                    forward = read_data
                elif sample in read_name and "R2" in read_name:
                    reverse = read_data

            mapping[sample] = (forward, reverse)
        return mapping

    def _check_pair_counts_match(self):
        for sample, sample_data in self.sample_mapping.items():
            forward_count = sample_data[0]['total_sequences']
            reverse_count = sample_data[1]['total_sequences']
            Flagger.flag(   message = f"Read Counts: {sample}: forward {forward_count}: reverse: {reverse_count}",
                            severity=20,
                            checkID="INFO")
            if forward_count != reverse_count:
                Flagger.flag(   message = f"Sample: {sample} has different forward and reverse reads counts",
                                severity=90,
                                checkID="R_0004")

    def _check_outliers(self):
        """ Checks for outliers across reads for the following:

            'percent_gc'
            'avg_sequence_length'
            'total_sequences'
            'percent_duplicates'
        """
        for metric in ['percent_gc',
                        'avg_sequence_length',
                        'total_sequences',
                        'percent_duplicates']:

            metric_values = {reads:data[0][metric]
                             for reads,data
                             in self.sample_mapping.items()}
            if self.paired_end:
                metric_values.update({reads:data[1][metric]
                                   for reads,data
                                   in self.sample_mapping.items()})

            log.debug(f"Starting {metric} outlier check")
            outliers = readsWise_outlier_check(metric_values, outlier_stdev=self.outlier_thresholds[metric])
            if outliers:
                log.error(f"FAIL: {metric} outliers {outliers}")
            log.debug(f"Finished {metric} outlier check")


    def _load_fastQC(self):
        data = dict()
        data['files_paths'] = [filepath
                                for filepath
                                in self.data['report_data_sources']['FastQC']['all_sections'].values()]
        data['files'] = [os.path.basename(filepath)
                        for filepath
                        in data['files_paths']]
        data['sample_reads'] = [sample
                                for sample
                                in self.data['report_data_sources']['FastQC']['all_sections'].keys()]

        return data



    def _json_multiQC(self, multiQC_zip_path: str) -> str:
        """ Unzips multiQC and places into a tmp contents folder.
        Returns path to multiQC json file.

        :param multiQC_zip_path: path to multiQC zip file
        """
        temp_dir = tempfile.mkdtemp()
        with zipfile.ZipFile(multiQC_zip_path, 'r') as zip_ref:
            zip_ref.extractall(temp_dir)
        return os.path.join(temp_dir, os.path.splitext(os.path.basename(multiQC_zip_path))[0], "multiqc_data.json")

def _quick_stats(values: [float]) -> Tuple[float,float,float]:
    """ Given a list of values returns Max, Median and Maximum

    :param values: values to compute stats for
    """
    return (max(values), median(values), min(values))


def _extract_general_stats(extract: str, data: dict) -> dict:
    """ Extracts data from sampleWise multiQC general stats.

    :param extract: The string to extract from report_general_stats_data
    :param data: multiQC report data as directly imported by json.load
    """
    extracted = dict()
    general_stats_by_sample = data["report_general_stats_data"][0]
    for sample, general_stats in general_stats_by_sample.items():
        extracted[sample] = general_stats[extract]
    return extracted
